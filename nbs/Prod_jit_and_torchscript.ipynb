{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Prod, jit and torchscript.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Deep Learning in Produnction, JIT and Python dependencies\n",
        "\n",
        "In computing, just-in-time (JIT) compilation (also dynamic translation or run-time compilations) is a way of executing computer code that involves compilation during execution of a program (at run time) rather than before execution. \n",
        "\n",
        "### TensorFlow1.0 and Graph execution\n",
        "Let's dive into this, compare the Python and Tensorflow outputs in the code below:\n",
        "\n",
        "```\n",
        "#Python\n",
        "a = 1\n",
        "b = 2\n",
        "c = a + b\n",
        "print(c)\n",
        ">>> 3\n",
        "\n",
        "#Tensorflow 1.0\n",
        "a = tf.Variable(1)\n",
        "b = tf.Variable(2)\n",
        "c = a + b\n",
        "print(c)\n",
        ">>> <tf.Variable ... shape()>\n",
        "```\n",
        "Wtf? Traditionally, Theano and consequently Tensorflow1.0 came with graph execution for JIT compilation as a default. This means that, when you define a variable in TF that variable is not evaluated but is rather a placeholder. This placeholder informs TF how variables are connected so that the program constructs a computation graph upon execution. **Specifically, `a = tf.Variable(1)` is just a placeholder.**\n",
        "\n",
        "The TF code above will only evaluate the value of c when `a tf.session()` is wrapped around the graph definition and then executed. For example:\n",
        "\n",
        "```\n",
        "a = tf.Variable(1)\n",
        "b = tf.Variable(2)\n",
        "x = tf.placeholder()\n",
        "yhat = a * x + b\n",
        "\n",
        "with tf.session() as session:\n",
        "  session.run(yhat, feed_dict={x:. 3})\n",
        "  print(yhat)\n",
        ">>> [0.5]\n",
        "```\n",
        "The above rewuirent is not pythonic and also generates the need for boilerplate code overhead. However, an additional mode for execution of operations as they are defined can be enabled i.e. eager mode, using `tf.compat.v1.enable_eager_execution()`. Nonetheless, jit compiling is significantly faster than eager mode which is crucial for models in production.\n",
        "\n",
        "\n",
        "### Pytorch and eager model\n",
        "Converesly, Pytorch comes with eager mode (as now in TF2.0) as default and constructs the computation graph dynamically. For example:\n",
        "\n",
        "```\n",
        "a = torch.tensor(1)\n",
        "b = torch.tensor(2)\n",
        "c = a + b\n",
        "print(c)\n",
        ">>> tensor(3)\n",
        "```\n",
        "\n",
        "This allows for \n",
        "- pythonic expression: models are object oriented python programs\n",
        "- hacking: use any python library\n",
        "- debugging and research: print, pdb debugger, REPL interpreter\n",
        "\n",
        "However, the above are an issue for production requirements in terms of portability (model serialisation and export to variety of enviroments) and performance (optimise graph execution for inference latency, throughput etc). For example, in terms of portability pytorch models are tightly coupled to Python's REPL interpreter. In terms of performance, python's restrictive dynamism allows for computational optimisation only to a certain extend and therefore high inference latency and low service throughput.\n",
        "\n",
        "### TorchScript\n",
        "\n",
        "To overcome these issues Pytorch comes with Torchscript. Torchscript's purpose is to port serializable and optimizable models from PyTorch code. Any TorchScript program can be saved from a Python process and loaded in a process where there is no Python dependency. \n",
        "\n",
        "Torchscript comes with a scipt and a tracing mode. For either modes the beneftis are \n",
        "1. The ability to serialize models and later run them outside of Python, via LibTorch, a C++ native module. In this way DL models  can be embedded in various production environments.\n",
        "2. The ability to compile jit-able modules rather than running them as an interpreter, allowing for various optimizations and performancem improvements, both during training and inference. This is equally helpful for development and production.\n",
        "\n",
        "See below an example of scripting a Pytorch model."
      ],
      "metadata": {
        "id": "xJukKqw7TXNO"
      }
    },
    {
      "metadata": {
        "id": "xlXQEqUEjLIU"
      },
      "cell_type": "markdown",
      "source": [
        "# Python on CPU"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = torch.randn(128, 3, 28, 28, requires_grad=True)\n",
        "y = torch.randint(0, 10, size=(128,))"
      ],
      "metadata": {
        "id": "6aAm7x1egunD"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yg_QMVmyZw5m"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.functional as F\n",
        "import torch.nn as nn\n",
        "\n",
        "class MyConv(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MyConv, self).__init__()\n",
        "        \n",
        "        self.convnet = nn.Sequential(\n",
        "            nn.Conv2d(3, 16, 3, padding=1),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(16, 32, 3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 64, 3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "        \n",
        "        self.linearnet = nn.Sequential(\n",
        "            nn.Linear(64*28*28, 1024),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(1024, 10),\n",
        "            nn.LogSoftmax(dim=1),\n",
        "        )\n",
        "        \n",
        "    def forward(self, x):\n",
        "        batch = x.size(0)\n",
        "        x = self.convnet(x)\n",
        "        x = x.reshape(batch, -1)\n",
        "        return x"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1nvuuAz0b_B_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24e2b6c7-a930-4abb-bc6b-7b217888e274"
      },
      "cell_type": "code",
      "source": [
        "model_python = MyConv()\n",
        "model_python"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MyConv(\n",
              "  (convnet): Sequential(\n",
              "    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU()\n",
              "    (3): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (5): ReLU()\n",
              "    (6): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (8): ReLU()\n",
              "  )\n",
              "  (linearnet): Sequential(\n",
              "    (0): Linear(in_features=50176, out_features=1024, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=1024, out_features=10, bias=True)\n",
              "    (3): LogSoftmax(dim=1)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "2_k_21Tud4lM"
      },
      "cell_type": "code",
      "source": [
        "loss_fn = torch.nn.NLLLoss()\n",
        "optimizer = torch.optim.Adam(params=model_python.parameters())\n",
        "\n",
        "def train():\n",
        "    y_pre = model_python(X)\n",
        "    loss = loss_fn(y_pre, y)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    print(\"loss: \", loss.detach().numpy())"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "metadata": {
        "id": "u5Wqc1DEeDcx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "931fc9d8-450d-4951-82ee-7a469137400c"
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "for _ in range(20):\n",
        "    train()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss:  -0.5149412\n",
            "loss:  -0.7885114\n",
            "loss:  -1.09506\n",
            "loss:  -1.4270493\n",
            "loss:  -1.7669119\n",
            "loss:  -2.0963206\n",
            "loss:  -2.4091487\n",
            "loss:  -2.703685\n",
            "loss:  -2.9786377\n",
            "loss:  -3.2331269\n",
            "loss:  -3.468272\n",
            "loss:  -3.6846206\n",
            "loss:  -3.882977\n",
            "loss:  -4.063745\n",
            "loss:  -4.22716\n",
            "loss:  -4.37317\n",
            "loss:  -4.503025\n",
            "loss:  -4.6171966\n",
            "loss:  -4.718364\n",
            "loss:  -4.8084326\n",
            "CPU times: user 8.28 s, sys: 266 ms, total: 8.55 s\n",
            "Wall time: 9.31 s\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "XUsXt_QNmi5T"
      },
      "cell_type": "markdown",
      "source": [
        "# Torch on CPU"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = torch.randn(128, 3, 28, 28, requires_grad=True)\n",
        "y = torch.randint(0, 10, size=(128,))"
      ],
      "metadata": {
        "id": "EpgCEITTf0ug"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "metadata": {
        "id": "W05POdCHfuH6"
      },
      "cell_type": "code",
      "source": [
        "class MyConv(torch.jit.ScriptModule):\n",
        "    def __init__(self):\n",
        "        super(MyConv, self).__init__()\n",
        "        \n",
        "        self.convnet = torch.jit.trace(nn.Sequential(\n",
        "            nn.Conv2d(3, 16, 3, padding=1),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(16, 32, 3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 64, 3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "        ), torch.randn(1, 3, 28, 28))\n",
        "        \n",
        "        self.linearnet = torch.jit.trace(nn.Sequential(\n",
        "            nn.Linear(64*28*28, 1024),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(1024, 10),\n",
        "            nn.LogSoftmax(dim=1),\n",
        "        ), torch.randn(1, 64*28*28))\n",
        "    \n",
        "    @torch.jit.script_method\n",
        "    def forward(self, x):\n",
        "        batch = x.size(0)\n",
        "        x = self.convnet(x)\n",
        "        x = x.reshape(batch, -1)\n",
        "        return x"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FCj74Kh7mywY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39e33688-f78b-463b-d240-35a55dba0e17"
      },
      "cell_type": "code",
      "source": [
        "model_torch = MyConv()\n",
        "MyConv()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MyConv(\n",
              "  (convnet): Sequential(\n",
              "    original_name=Sequential\n",
              "    (0): Conv2d(original_name=Conv2d)\n",
              "    (1): BatchNorm2d(original_name=BatchNorm2d)\n",
              "    (2): ReLU(original_name=ReLU)\n",
              "    (3): Conv2d(original_name=Conv2d)\n",
              "    (4): BatchNorm2d(original_name=BatchNorm2d)\n",
              "    (5): ReLU(original_name=ReLU)\n",
              "    (6): Conv2d(original_name=Conv2d)\n",
              "    (7): BatchNorm2d(original_name=BatchNorm2d)\n",
              "    (8): ReLU(original_name=ReLU)\n",
              "  )\n",
              "  (linearnet): Sequential(\n",
              "    original_name=Sequential\n",
              "    (0): Linear(original_name=Linear)\n",
              "    (1): ReLU(original_name=ReLU)\n",
              "    (2): Linear(original_name=Linear)\n",
              "    (3): LogSoftmax(original_name=LogSoftmax)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "metadata": {
        "id": "qR6lzq9Jm_jX"
      },
      "cell_type": "code",
      "source": [
        "loss_fn = torch.nn.NLLLoss()\n",
        "optimizer = torch.optim.Adam(params=model_torch.parameters())\n",
        "\n",
        "def train_jit():\n",
        "    y_pre = model_torch(X)\n",
        "    loss = loss_fn(y_pre, y)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    print(\"loss: \", loss.detach().numpy())"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gxTIsy6nnGu4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "140a4e75-0736-480d-8506-1c26aeb2e16c"
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "for _ in range(20):\n",
        "    train_jit()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss:  -0.32451892\n",
            "loss:  -0.5912205\n",
            "loss:  -0.89638066\n",
            "loss:  -1.2159026\n",
            "loss:  -1.5312963\n",
            "loss:  -1.8265008\n",
            "loss:  -2.1042957\n",
            "loss:  -2.3606114\n",
            "loss:  -2.5947688\n",
            "loss:  -2.8110933\n",
            "loss:  -3.0142124\n",
            "loss:  -3.2080374\n",
            "loss:  -3.3949592\n",
            "loss:  -3.5764592\n",
            "loss:  -3.7519906\n",
            "loss:  -3.9212832\n",
            "loss:  -4.0830455\n",
            "loss:  -4.235887\n",
            "loss:  -4.3776855\n",
            "loss:  -4.50814\n",
            "CPU times: user 7.95 s, sys: 161 ms, total: 8.11 s\n",
            "Wall time: 8.03 s\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "sDsTNkqwjUmk"
      },
      "cell_type": "markdown",
      "source": [
        "# Python on GPU"
      ]
    },
    {
      "metadata": {
        "id": "uySSskM-jJ5U"
      },
      "cell_type": "code",
      "source": [
        "model_python.to(\"cuda\")\n",
        "optimizer = torch.optim.Adam(params=model_python.parameters())"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hffmJGaOjqEF"
      },
      "cell_type": "code",
      "source": [
        "def train_gpu():\n",
        "    y_pre = model_python(X.to(\"cuda\"))\n",
        "    loss = loss_fn(y_pre, y.to(\"cuda\"))\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    print(\"loss: \", loss.to(\"cpu\").detach().numpy())"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SQzE3HAVj0mN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e762cbc0-be3f-4c19-9a07-283909c9e335"
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "for _ in range(20):\n",
        "    train_gpu()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss:  -4.3880954\n",
            "loss:  -4.534538\n",
            "loss:  -4.658385\n",
            "loss:  -4.766274\n",
            "loss:  -4.862524\n",
            "loss:  -4.9499626\n",
            "loss:  -5.0297465\n",
            "loss:  -5.103152\n",
            "loss:  -5.171183\n",
            "loss:  -5.234377\n",
            "loss:  -5.2934456\n",
            "loss:  -5.349206\n",
            "loss:  -5.401966\n",
            "loss:  -5.4523873\n",
            "loss:  -5.501034\n",
            "loss:  -5.5479217\n",
            "loss:  -5.593396\n",
            "loss:  -5.6380644\n",
            "loss:  -5.68185\n",
            "loss:  -5.72521\n",
            "CPU times: user 597 ms, sys: 16.7 ms, total: 614 ms\n",
            "Wall time: 752 ms\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "8tKno7gEnQwU"
      },
      "cell_type": "markdown",
      "source": [
        "# torch on GPU"
      ]
    },
    {
      "metadata": {
        "id": "Ymqab-5in9-O"
      },
      "cell_type": "code",
      "source": [
        "class MyConv(torch.jit.ScriptModule):\n",
        "    def __init__(self):\n",
        "        super(MyConv, self).__init__()\n",
        "        \n",
        "        self.convnet = torch.jit.trace(nn.Sequential(\n",
        "            nn.Conv2d(3, 16, 3, padding=1),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(16, 32, 3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 64, 3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "        ).to(\"cuda\"), torch.randn(1, 3, 28, 28, device=\"cuda\"))\n",
        "        \n",
        "        self.linearnet = torch.jit.trace(nn.Sequential(\n",
        "            nn.Linear(64*28*28, 1024),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(1024, 10),\n",
        "            nn.LogSoftmax(dim=1),\n",
        "        ).to(\"cuda\"), torch.randn(1, 64*28*28, device=\"cuda\"))\n",
        "    \n",
        "    @torch.jit.script_method\n",
        "    def forward(self, x):\n",
        "        batch = x.size(0)\n",
        "        x = self.convnet(x)\n",
        "        x = x.reshape(batch, -1)\n",
        "        return x\n",
        "    \n",
        "model_torch = MyConv()\n",
        "optimizer = torch.optim.Adam(params=model_torch.parameters())"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "metadata": {
        "id": "J-xfLvbzoDJD"
      },
      "cell_type": "code",
      "source": [
        "def train_jit_gpu():\n",
        "    y_pre = model_torch(X.to(\"cuda\"))\n",
        "    loss = loss_fn(y_pre, y.to(\"cuda\"))\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    print(\"loss: \", loss.to(\"cpu\").detach().numpy())"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "metadata": {
        "id": "N05LD_wuuHWs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "194c1f0d-8251-4db3-d39f-d172205eab6a"
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "for _ in range(20):\n",
        "    train_jit_gpu()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss:  -0.38337812\n",
            "loss:  -0.69447917\n",
            "loss:  -1.0345545\n",
            "loss:  -1.3835523\n",
            "loss:  -1.7232059\n",
            "loss:  -2.0454595\n",
            "loss:  -2.3477736\n",
            "loss:  -2.6333952\n",
            "loss:  -2.9032087\n",
            "loss:  -3.1584203\n",
            "loss:  -3.4010634\n",
            "loss:  -3.6302164\n",
            "loss:  -3.8446865\n",
            "loss:  -4.0430136\n",
            "loss:  -4.22342\n",
            "loss:  -4.3851805\n",
            "loss:  -4.529235\n",
            "loss:  -4.656223\n",
            "loss:  -4.76757\n",
            "loss:  -4.866083\n",
            "CPU times: user 1.11 s, sys: 34.5 ms, total: 1.14 s\n",
            "Wall time: 1.39 s\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "JNsP1conubwX"
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rZStyH3UcC9W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d76e012-973c-4bcd-ca06-dff5d5464e77"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "y"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([4, 6, 6, 1, 8, 9, 0, 0, 9, 7, 1, 8, 0, 4, 6, 4, 4, 1, 3, 2, 3, 4, 3, 1,\n",
              "        9, 7, 9, 5, 4, 3, 9, 6, 0, 8, 5, 2, 9, 2, 2, 5, 7, 8, 6, 7, 8, 1, 7, 6,\n",
              "        7, 8, 1, 1, 1, 7, 4, 9, 4, 6, 2, 1, 0, 8, 3, 2, 8, 5, 4, 0, 0, 9, 1, 4,\n",
              "        5, 1, 1, 5, 6, 1, 8, 5, 0, 0, 5, 8, 4, 9, 7, 0, 5, 4, 7, 0, 6, 9, 5, 6,\n",
              "        2, 8, 9, 5, 6, 1, 7, 6, 4, 0, 3, 4, 4, 5, 0, 3, 1, 8, 9, 4, 9, 6, 8, 0,\n",
              "        3, 0, 0, 6, 0, 8, 6, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    }
  ]
}
